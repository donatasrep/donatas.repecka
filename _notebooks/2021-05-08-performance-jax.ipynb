{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrE1kciUIxD5"
   },
   "source": [
    "# Performance Analysis -  Jax\n",
    "> Number of effective sequences implemented in Tensorflow\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- author: Donatas RepeÄka\n",
    "- categories: [performance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVXv9X4d_dND"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skMnA5NeIU4O"
   },
   "source": [
    "In [the previous post](https://donatasrep.github.io/donatas.repecka/performance/2021/04/27/Performance-comparison.html) I have compared various languages and libraries in terms of their speed. This notebook contains the code used in the comparison as well as some details about the choices made to improve the performance of Jax implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/donatasrep/donatas.repecka/blob/master/data/picked_msa.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip\n",
    "# ! pip install numpy\n",
    "# ! pip install pandas\n",
    "# ! pip install --upgrade jax jaxlib\n",
    "# ! pip install --upgrade jax jaxlib==0.1.66+cuda111 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    fasta_df = pd.read_csv(path, sep=\"\\n\", lineterminator=\">\", index_col=False, names=['id', 'seq'])\n",
    "    return fasta_df.seq.to_numpy(dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = get_data('../data/picked_msa.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to remind the pseudo code looks like this:\n",
    "\n",
    "```\n",
    "for seq1 in seqs:\n",
    "  for seq2 in seqs:\n",
    "    if count_mathes(seq1, seq2) > threshold:\n",
    "      weight +=1\n",
    "  meff += 1/weight\n",
    " \n",
    "meff = meff/(len(seq1)^0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import jit as jax_jit\n",
    "from jax import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax_jit\n",
    "def get_nf_jax_pair(a, b, threshold=0.8,batch_size=1):\n",
    "    return  jnp.equal(a, b).mean(-1) > threshold\n",
    "\n",
    "@jax_jit\n",
    "def get_nf_jax_gpu(seqs):\n",
    "    n_seqs, seq_len = seqs.shape      \n",
    "    out = vmap(get_nf_jax_single, (0, None))(seqs, seqs)\n",
    "    return jnp.sum(out) /(seq_len**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_ = seqs[:100]\n",
    "get_nf_jax_gpu(seqs_.view(np.uint32).reshape(seqs_.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "seqs_ = seqs[:100]\n",
    "get_nf_tf(seqs_.view(np.uint32).reshape(seqs_.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_ = seqs[:100]\n",
    "get_nf_tf(seqs_.view(np.uint32).reshape(seqs_.shape[0], -1), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "with tf.device('/cpu:0'):\n",
    "    get_nf_tf(seqs_.view(np.uint32).reshape(seqs_.shape[0], -1), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple points:\n",
    "* Jax does not support Windows\n",
    "* It is signficantly fater than Pytorch and Tensorflow and I am not entirely sure why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020-04-08-spectral-norm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
