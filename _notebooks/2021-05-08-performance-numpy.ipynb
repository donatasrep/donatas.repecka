{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrE1kciUIxD5"
   },
   "source": [
    "# Performance Analysis -  Numpy\n",
    "> Number of effective sequences implemented in Numpy\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- author: Donatas Repečka\n",
    "- categories: [performance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVXv9X4d_dND"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skMnA5NeIU4O"
   },
   "source": [
    "In [the previous post](https://donatasrep.github.io/donatas.repecka/performance/2021/04/27/Performance-comparison.html) I have compared various languages and libraries in terms of their speed. This notebook contains the code used in the comparison as well as some details about the choices made to improve the performance of numpy implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/donatasrep/donatas.repecka/blob/master/data/picked_msa.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will cheat here and use pandas to help me to read the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    fasta_df = pd.read_csv(path, sep=\"\\n\", lineterminator=\">\", index_col=False, names=['id', 'seq'])\n",
    "    return fasta_df.seq.to_numpy(dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = get_data('../data/picked_msa.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to remind the pseudo code looks like this:\n",
    "\n",
    "```\n",
    "for seq1 in seqs:\n",
    "  for seq2 in seqs:\n",
    "    if count_mathes(seq1, seq2) > threshold:\n",
    "      weight +=1\n",
    "  meff += 1/weight\n",
    " \n",
    "meff = meff/(len(seq1)^0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Numpy implementation is based on pure python implementation which can be found [here](https://donatasrep.github.io/donatas.repecka/performance/2021/05/08/performance-pure-python.html). \n",
    "\n",
    "The main differences are:\n",
    "* uses numpy arrays and operators. \n",
    "* sequences are in vectorised fashion using `np.equal` rather than looping over each element in the sequence.\n",
    "* sequences are converted to arrays of integers rather than characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_nf_python_numpy(seqs, threshold=0.8):\n",
    "    seqs = seqs.view(np.uint32).reshape(seqs.shape[0], -1)\n",
    "    n_seqs = len(seqs)\n",
    "    is_same_cluster = np.ones([n_seqs, n_seqs], np.bool_) \n",
    "    for i in range(n_seqs):\n",
    "        for j in range(i+1, n_seqs):\n",
    "            identity = np.equal(seqs[i], seqs[j]).mean()\n",
    "            is_more = np.greater(identity, threshold)\n",
    "            is_same_cluster[i,j] = is_more\n",
    "            is_same_cluster[j,i] = is_more\n",
    "    meff = 1.0/np.sum(is_same_cluster,1)\n",
    "    return meff.sum()/(seqs.shape[-1]**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 ms ± 2.95 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "get_nf_python_numpy(seqs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18006706787628665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nf_python_numpy(seqs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although performance gain is substantial, I still have two loops which is one of the first things you want to tackle when trying to improve algorithm speed. In practise, you want to use vectorization to take advantage of CPU ability to perform the same operation on vectors. \n",
    "\n",
    "Ideally, I would like to do all to all pairwise comparison in one vectorized operation. Unfortunately, this is not a viable option due to memory constraints . Such operation will require `n * n * l` size matrix. In my case, that  would result into ~70GB size matrix (n = 10000, l = 683, boolean uses 1 byte)\n",
    "\n",
    "$$10000^2 *683 = 68.3*10^9 \\ bytes = 68.3 \\ gigabytes$$\n",
    "\n",
    "To be able to run such an algorithm on an everyday computer, the memory requirement has to be lower. Usually, this can be solved with batching, taking only a portion of data at the time. In this case, I will perform a one-to-all comparison at the time. This will require `n*l` memory which is 10000 (~7MB)  times less than for the all-to-all version. \n",
    "\n",
    "\n",
    "Note, I still can exploit the fact that the matrix of identity is symmetric which means that only the first iteration has to be done with `n-1` sequences, the second sequence needs only be compared with `n-2` and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_to_all_comparison(seqs, threshold=0.8):\n",
    "    pairwise_id = np.equal(seqs[1:], seqs[0].T).mean(1)\n",
    "    return pairwise_id > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nf_numpy_v2(seqs):\n",
    "    seqs = seqs.view(np.uint32).reshape(seqs.shape[0], -1)\n",
    "    n_seqs, seq_len = seqs.shape\n",
    "    is_same_cluster = np.ones([n_seqs, n_seqs],np.bool_)\n",
    "    for i in range(n_seqs-1):\n",
    "        out = get_one_to_all_comparison(seqs[i:])\n",
    "        is_same_cluster[i, i+1:] = out\n",
    "        is_same_cluster[i+1:, i] = out\n",
    "    s = 1.0/is_same_cluster.sum(1)\n",
    "    return s.sum()/(seq_len**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.8 ms ± 2.97 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "get_nf_numpy_v2(seqs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using numpy, the algorithm's runtime decreases significantly. The gain on 1% of the data is roughly 100 times (might differ depending on the hardware). The improvement will scale with the amount of data that is being processed so on the data set  the gain will be even larger. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a limit to how much an algorithm can be improved. However, more speed can be gained by simply exploiting the sheer size of infrastructure, i.e. multiple CPUs/machines. Unfortunately, this rarely happens automatically, unless you use libraries that have this ability built-in. Although Numpy has some functionality that runs multi-threaded, in this case some additional work is required. \n",
    "\n",
    "In this case, sequence comparison does not need to be performed sequentially, thus can be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import sharedctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = seqs[:100].view(np.uint32).reshape(100, -1)\n",
    "n_seqs, seq_len = seqs.shape\n",
    "\n",
    "global_is_same_cluster = np.ctypeslib.as_ctypes(np.ones([n_seqs, n_seqs],np.bool_))\n",
    "shared_global_is_same_cluster = sharedctypes.RawArray(global_is_same_cluster._type_, global_is_same_cluster)\n",
    "\n",
    "def get_nf_numpy_global(i, threshold=0.8):\n",
    "    out = get_one_to_all_comparison(seqs[i:])\n",
    "    tmp = np.ctypeslib.as_array(shared_global_is_same_cluster)\n",
    "    tmp[i, i+1:] = out\n",
    "    tmp[i+1:, i] = out\n",
    "\n",
    "def get_nf_multi_threaded(threads=None):\n",
    "    with multiprocessing.Pool(threads) as pool:\n",
    "        pool.map(get_nf_numpy_global, range(n_seqs))\n",
    "    global_is_same_cluster = np.ctypeslib.as_array(shared_global_is_same_cluster)\n",
    "    meff = 1.0/global_is_same_cluster.sum(1)\n",
    "    return meff.sum()/(seq_len**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the nicest solution, I have to admit, but that still demonstrates the power of having multithreading enabled.\n",
    "\n",
    "Note, IPython on Windows struggles with multiprocessing and this code will not work [IPython on Windows struggles with multiprocessing and this code will not work](https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020-04-08-spectral-norm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
