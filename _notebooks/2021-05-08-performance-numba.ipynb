{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrE1kciUIxD5"
   },
   "source": [
    "# Performance Analysis -  Numba\n",
    "> Number of effective sequences implemented in Numba\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- author: Donatas Repečka\n",
    "- categories: [performance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVXv9X4d_dND"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skMnA5NeIU4O"
   },
   "source": [
    "In [the previous post](https://donatasrep.github.io/donatas.repecka/performance/2021/04/27/Performance-comparison.html) I have compared various languages and libraries in terms of their speed. This notebook contains the code used in the comparison as well as some details about the choices made to improve the performance of numba implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Numba [website](http://numba.pydata.org/): \"Numba translates Python functions to optimized machine code at runtime using the industry-standard LLVM compiler library. Numba-compiled numerical algorithms in Python can approach the speeds of C or FORTRAN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/donatasrep/donatas.repecka/blob/master/data/picked_msa.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install pandas\n",
    "# ! pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    fasta_df = pd.read_csv(path, sep=\"\\n\", lineterminator=\">\", index_col=False, names=['id', 'seq'])\n",
    "    return fasta_df.seq.to_numpy(dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = get_data('../data/picked_msa.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to remind the pseudo code looks like this:\n",
    "\n",
    "```\n",
    "for seq1 in seqs:\n",
    "  for seq2 in seqs:\n",
    "    if count_mathes(seq1, seq2) > threshold:\n",
    "      weight +=1\n",
    "  meff += 1/weight\n",
    " \n",
    "meff = meff/(len(seq1)^0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Numpy and Python versions, we use the same input data. The code is closer to the version of pure Python because wrapping optimised Numpy code turned out to be slower. It seems that you are  better off leaving all optimisation for Numba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nf_numba(seqs, threshold=0.8):\n",
    "    seqs = seqs.view(np.uint32).reshape(seqs.shape[0], -1)\n",
    "    n_seqs, seq_len = seqs.shape\n",
    "    is_same_cluster = np.eye(n_seqs)\n",
    "    for i in prange(n_seqs):\n",
    "        c  = 0\n",
    "        for j in prange(i+1, n_seqs):\n",
    "            identity = np.equal(seqs[i], seqs[j]).mean()\n",
    "            is_more = np.greater(identity, threshold)\n",
    "            is_same_cluster[i,j] = is_more\n",
    "            is_same_cluster[j,i] = is_more\n",
    "    meff = 1.0/is_same_cluster.sum(1)\n",
    "    return meff.sum()/(seq_len**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things that need to be done in order to utilise Numba fully. Firstly,  Numba uses JIT -(just in time compilation)[https://en.wikipedia.org/wiki/Just-in-time_compilation]. Hence you need to wrap your functions with either `@jit` or ‘jit’ function. Note, the first run of the wrapped function will be slower as Numba needs to compile code. Secondly, there is the `nopython` option that bypasses the Python interpreter. It has its own down sides that allows code to run faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18006706787628668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = jit(get_nf_numba, nopython=True,parallel=False)\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ms ± 642 µs per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another really nice feature of Numba is that it allows to parallelise code with one single option as you can see below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18006706787628668"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = jit(get_nf_numba, nopython=True,parallel=True)\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11 ms ± 3.13 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if precision is less important and can be sacrificed for extra speed, there is `fastmath`option. From (Numba documentation)[https://numba.readthedocs.io/en/stable/user/performance-tips.html?highlight=fastmath#fastmath]: \n",
    "\n",
    "“In certain classes of applications strict IEEE 754 compliance is less important. As a result it is possible to relax some numerical rigour with view of gaining additional performance. The way to achieve this behaviour in Numba is through the use of the fastmath keyword argument”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18006706787628665"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = jit(get_nf_numba, nopython=True,parallel=True, fastmath=True)\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.90 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.31 ms ± 3.63 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "fn(seqs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba seemed to be the fastest library that I tried on CPU and was relatively easy to get started. Of course, there will be cases where Numba will not work, but in general it seems that Numba deserves to be at least considered seriously when looking for ways to improve performance of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020-04-08-spectral-norm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
